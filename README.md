# PreProd-Corp-Buildathon-2024-Algorithm-Avengers

### This is the main Production Repository for Avenge-AI

---

## Table of Contents
1. [Homepage and Login Page](#homepage-and-login-page)
2. [User Task Page](#user-task-page)
3. [Development and Pre-Production Repositories](#development-and-pre-production-repositories)
4. [Dependencies](#dependencies)
5. [Installation](#installation)
6. [User Interactions](#user-operations)

---

## Homepage and Login Page

![Homepage Screenshot](https://github.com/user-attachments/assets/25c6edfc-c8a7-40c4-aa3f-cdb6581d449f)
![Login Page Screenshot](https://github.com/user-attachments/assets/5179cb35-3dd8-48be-87dc-bbf99c7aad3c)

## User Task Page

![image](https://github.com/user-attachments/assets/d3771fa1-8e08-48b0-b074-d2da18a0c6a2)


## Development and Pre-Production Repositories

- **Web**: [HACKATHON-FRONT-AND-NODE](https://github.com/aryanshdev/HACKATHON-FRONT-AND-NODE)
- **ML Model**: [HACKATHON-MODEL](https://github.com/aryanshdev/HACKATHON-MODEL)

## Dependencies

### Frontend Dependencies
- Ensure you have Node.js installed.
- Run the following command in the frontend folder:
  ```bash
  npm install

### Backend Dependencies
- Ensure you have Node.js installed.
- Run the following command in the backend folder:
  ```bash
  npm install

### ML Model Dependencies
- Ensure you have Python installed.
- Run the following command in the Models folder:
  ```bash
  pip install -r models/requirements.txt

## User Operations

### Upload Data
- Upload Data (dataset file)

### Data Transformation: Functions
1. **Clean Columns**
2. **Remove Duplicates**
3. **Check Missing Values**
4. **Handle Missing Non-Numeric Data**
5. **Handle Missing Numeric Data**
6. **Convert the Data to Numeric**
7. **Normalize Date Column**
8. **One-Hot Encoding (for specific columns)**
9. **Get Column Data Types**
10. **Drop Rows Without Target**

*Generate and Display Outputs each time*

### Model Training
1. **SVM Model**
   - Parameters: kernel, C, gamma

2. **Random Forest**
   - Parameters: n-estimators, max depth, minSampleSplit

3. **XGBoost**
   - Parameters: n-estimators, max depth, learning rate

4. **Decision Tree**
   - Parameters: max depth, minSampleSplit, kernel

5. **Bagging**
   - Parameters: n-estimators, Max sample, Max feature

*Outputs:*
- Accuracy (test and train)
